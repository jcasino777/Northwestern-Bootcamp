{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "# https://splinter.readthedocs.io/en/latest/drivers/chrome.html\n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrape mars news\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull classes for articles and paragraphs\n",
    "articles = soup.find_all('div', class_='content_title')\n",
    "paragraphs = soup.find_all('div', class_='article_teaser_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append scrape to list\n",
    "title_list = []\n",
    "paragraph_list = []\n",
    "for title in articles:\n",
    "    title_list.append(title.text.strip())\n",
    "\n",
    "for para in paragraphs:\n",
    "    paragraph_list.append(para.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape featured image\n",
    "url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov//spaceimages/images/mediumsize/PIA17044_ip.jpg'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return featured image url\n",
    "featured_image = soup.find_all('a', class_='button fancybox')\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/' + featured_image[0]['data-fancybox-href']\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape weather data\n",
    "url3 = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull all weather data, drop non-weather tweets, store as list\n",
    "all_weather = soup.find_all('p', class_='TweetTextSize TweetTextSize--normal js-tweet-text tweet-text')\n",
    "weather_list =[]\n",
    "for day in all_weather:\n",
    "    weather_list.append(day.text.strip())\n",
    "\n",
    "weather_list_df = pd.DataFrame(weather_list,columns = ['Weather'])\n",
    "weather_list_df['drop'] = weather_list_df.Weather.str.split().str.get(0)\n",
    "reduced_weather_list_df = weather_list_df.loc[weather_list_df['drop'] == \"InSight\"]\n",
    "reduced_weather_list_df = reduced_weather_list_df['Weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 169 (2019-05-18) low -100.6ºC (-149.1ºF) high -17.6ºC (0.4ºF)\\nwinds from the S at 4.6 m/s (10.2 mph) gusting to 15.5 m/s (34.7 mph)\\npressure at 7.50 hPapic.twitter.com/QKbNMc35Ia'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save latest weather data\n",
    "mars_weather = reduced_weather_list_df[0]\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                      0                              1\n",
       " 0  Equatorial Diameter:                       6,792 km\n",
       " 1       Polar Diameter:                       6,752 km\n",
       " 2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       " 3                Moons:            2 (Phobos & Deimos)\n",
       " 4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
       " 5         Orbit Period:           687 days (1.9 years)\n",
       " 6  Surface Temperature:                  -153 to 20 °C\n",
       " 7         First Record:              2nd millennium BC\n",
       " 8          Recorded By:           Egyptian astronomers]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull mars facts using pandas \n",
    "url4 = 'https://space-facts.com/mars/'\n",
    "tables = pd.read_html(url4)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull full size pics of mars\n",
    "url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url5)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://astrogeology.usgs.gov//search/map/Mars/Viking/cerberus_enhanced',\n",
       " 'https://astrogeology.usgs.gov//search/map/Mars/Viking/schiaparelli_enhanced',\n",
       " 'https://astrogeology.usgs.gov//search/map/Mars/Viking/syrtis_major_enhanced',\n",
       " 'https://astrogeology.usgs.gov//search/map/Mars/Viking/valles_marineris_enhanced']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of links to loop through\n",
    "links = soup.find_all('div', class_='item')\n",
    "\n",
    "url_list = []\n",
    "for link in links:\n",
    "     url_list.append(link.find('a')['href'])\n",
    "\n",
    "full_url_list = ['https://astrogeology.usgs.gov/' + url for url in url_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through links, pull title and image url as a dictionary, and append to list\n",
    "dict_placeholder = {}\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "for url in full_url_list:\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    dict_placeholder['title'] = soup.find('title').text.strip()\n",
    "    dict_placeholder['img_url'] = soup.find('li')('a')[0]['href']\n",
    "    hemisphere_image_urls.append(dict_placeholder)\n",
    "#     title_list.append(soup.find('title').text.strip())\n",
    "#     image_url_list.append(soup.find('li')('a')[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that I did not complete Part 2 of this Homework. I am aware of the repurcussions, and willing to accept\n",
    "# whatever penalty that you deem appropriate. \n",
    "\n",
    "# On a more philasophical note, I am less interested in course grade/certificate, and more interested in my own\n",
    "# personal development. On this front, I am very satisfied with my growth thus far. In fact, I am beginning \n",
    "# to not only implement my learnings at work, but I am now able to communicate with the 'quants' and even \n",
    "# provide direction to more novice coders. \n",
    "\n",
    "# With the above in mind, I have no interest in html and web development. Consequently, over the past few weeks, I've \n",
    "# largely been absent from classtime activities, instead exploring topics more applicable to my career and desired\n",
    "# skillset (exploring Kaggle, statistics, trading applications, sklearn, seaborn)\n",
    "\n",
    "# In the spirit of self-directed academia, I hope that you can understand my choice. It is not my intention to dismiss\n",
    "# these topics as 'unimportant' - instead it is my attempt to customize my learning, and maintain optimal effiency\n",
    "# in a world devoid of free-time\n",
    "\n",
    "# I fully intent to resume full attention upon the onset of Java, Plotly, Tableau, Machine Learning, and BigData topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
